# Multimodal Image + OCR Classifier

This project implements a multimodal classification pipeline using images and OCR (text) data. The model uses ResNet18 for image features and TF-IDF for text features, combined for final classification.

## ðŸ§  Features

- Uses both image and OCR text data for classification
- Built with PyTorch and Scikit-learn
- ResNet18 pretrained on ImageNet
- Custom PyTorch `Dataset` class for multimodal input
- Supports early stopping and model checkpointing

---

### 1. Clone the Repository
```
As per the shared mode 
Github--> git clone url
drive--> download and continue
```

### 2. Create a virtual environment and activate it:
```
python -m venv venv
source venv/bin/activate (for linux)
venv\Scripts\activate (for windows)
```
### 3.Install the required libraries:

```
pip install requirements.txt 
```

## Project structure



project_root/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ class_name_0/
â”‚   â”‚   â”œâ”€â”€ class_name_2/
â”‚   â”‚   â”œâ”€â”€ class_name_4/
â”‚   â”‚   â”œâ”€â”€ class_name_6/
â”‚   â”‚   â””â”€â”€ class_name_9/
â”‚   â””â”€â”€ ocr/
â”‚       â”œâ”€â”€ class_name_0/
â”‚       â”œâ”€â”€ class_name_2/
â”‚       â”œâ”€â”€ class_name_4/
â”‚       â”œâ”€â”€ class_name_6/
â”‚       â””â”€â”€ class_name_9/
â”‚
â”œâ”€â”€ notebook/
â”‚   â”œâ”€â”€ best_model_v4.pth
â”‚   â””â”€â”€ hybrid_v4.ipynb
â”‚
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ README.txt
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ classification_statistics.txt
â”‚
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ saved_models/
    â””â”€â”€ best_model_weights_v4.pth